{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e20063-0977-47f9-bead-897281c97534",
   "metadata": {},
   "source": [
    "# Clustering Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49040444-7784-4a39-a7e5-f3085e2cdf7f",
   "metadata": {},
   "source": [
    "### Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "attachments": {
    "43181ba1-bfed-47b1-b82b-379e2de4f16d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2213fa1c-3d61-4228-b68e-0ecdf84da75e",
   "metadata": {},
   "source": [
    "A contingency matrix, also known as a confusion matrix, is a table that visualizes the performance of a classification model. It presents a summary of the predicted and actual classes and helps assess the model's accuracy.\n",
    "\n",
    "### Structure of a Contingency Matrix:\n",
    "\n",
    "A standard 2x2 contingency matrix looks like this:\n",
    "![image.png](attachment:43181ba1-bfed-47b1-b82b-379e2de4f16d.png)\n",
    "\n",
    "### Evaluation of Model Performance:\n",
    "\n",
    "- **True Positive (TP)**: Instances where the model correctly predicts a positive class.\n",
    "- **True Negative (TN)**: Instances where the model correctly predicts a negative class.\n",
    "- **False Positive (FP)**: Instances where the model predicts positive but the actual class is negative (Type I error).\n",
    "- **False Negative (FN)**: Instances where the model predicts negative but the actual class is positive (Type II error).\n",
    "\n",
    "### Model Evaluation Metrics Derived from Contingency Matrix:\n",
    "\n",
    "1. **Accuracy**: Overall correctness of the model (sum of TP and TN divided by total).\n",
    "2. **Precision**: Proportion of true positive predictions among all positive predictions (TP / (TP + FP)).\n",
    "3. **Recall (Sensitivity)**: Proportion of actual positives correctly predicted (TP / (TP + FN)).\n",
    "4. **Specificity**: Proportion of actual negatives correctly predicted (TN / (TN + FP)).\n",
    "5. **F1 Score**: The harmonic mean of precision and recall, balances precision and recall.\n",
    "6. **False Positive Rate (FPR)**: The ratio of false positives to actual negatives (FP / (FP + TN)).\n",
    "\n",
    "Contingency matrices are fundamental in understanding the performance of a classification model by dissecting correct and incorrect predictions, aiding in the calculation of various evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9b7d7-fa25-4b95-8a41-03c88b33150b",
   "metadata": {},
   "source": [
    "### Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222ff5f3-cd11-4a0e-8d22-1aa26605456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_labels = [1, 0, 1, 1, 0, 1]\n",
    "predicted_labels = [1, 1, 1, 0, 0, 1]\n",
    "\n",
    "# Creating the confusion matrix\n",
    "confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7669130c-6bfe-474e-8506-5e199f83dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 8],\n",
       "       [8, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import pair_confusion_matrix\n",
    "\n",
    "\n",
    "true_labels = [1, 0, 1, 1, 0, 1]\n",
    "predicted_labels = [1, 1, 1, 0, 0, 1]\n",
    "\n",
    "pair_confusion_matrix(true_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7371934-fffa-4673-b75a-3fcace0ab128",
   "metadata": {},
   "source": [
    "## Let's understand both the matrix:\n",
    "\n",
    "## Regular Confusion Matrix\n",
    "\n",
    "The array represents a confusion matrix with a 2x2 shape. In a binary classification setting, a confusion matrix consists of four elements:\n",
    "\n",
    "- **True Positives (TP)**: Predicted as positive and actually positive.\n",
    "- **False Positives (FP)**: Predicted as positive but actually negative.\n",
    "- **True Negatives (TN)**: Predicted as negative and actually negative.\n",
    "- **False Negatives (FN)**: Predicted as negative but actually positive.\n",
    "\n",
    "In this case:\n",
    "\n",
    "- The top-left element (1) represents the count of True Negatives (TN).\n",
    "- The top-right element (1) represents the count of False Positives (FP).\n",
    "- The bottom-left element (1) represents the count of False Negatives (FN).\n",
    "- The bottom-right element (3) represents the count of True Positives (TP).\n",
    "\n",
    "This matrix suggests the following classification performance:\n",
    "\n",
    "- The model correctly predicted the negative class (0 or \"not the target class\") 1 time.\n",
    "- The model incorrectly predicted the positive class (1 or \"the target class\") 1 time while it was not.\n",
    "- The model incorrectly predicted the negative class 1 time when it was actually the positive class.\n",
    "- The model correctly predicted the positive class 3 times.\n",
    "\n",
    "## Pair Confusion Matrix\n",
    "\n",
    "- **Top-Left (Element at [0, 0]):** This value (8) represents the count of true negatives (TN), instances where the model correctly predicts the first class (let's call it class A) when the true label is not class A.\n",
    "\n",
    "- **Top-Right (Element at [0, 1]):** This value (8) represents the count of false positives (FP), instances where the model predicts class A but the true label is not class A.\n",
    "\n",
    "- **Bottom-Left (Element at [1, 0]):** This value (8) represents the count of false negatives (FN), instances where the model predicts a non-class A when the true label is class A.\n",
    "\n",
    "- **Bottom-Right (Element at [1, 1]):** This value (6) represents the count of true positives (TP), instances where the model correctly predicts class A.\n",
    "\n",
    "In this context, assuming class A is represented by the row/column index 0 and the other class by index 1, the pair confusion matrix indicates that:\n",
    "\n",
    "- The model correctly identified the non-class A instances 8 times.\n",
    "- The model correctly identified class A instances 6 times.\n",
    "- The model misclassified 8 non-class A instances as class A.\n",
    "- The model misclassified 8 class A instances as non-class A.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d5090-aa50-404e-be98-0353fc4a51de",
   "metadata": {},
   "source": [
    "### Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6d86b-e229-41cb-bcb5-783b21e4522e",
   "metadata": {},
   "source": [
    "Extrinsic measures evaluate a model’s performance based on its performance in real-world applications or specific tasks rather than assessing the model in isolation. These measures are task-specific and consider the model's performance in an end-use case scenario, which often involves complex NLP tasks like sentiment analysis, machine translation, named entity recognition, question answering, text summarization, and more.\n",
    "\n",
    "These measures rely on task-specific evaluation criteria and metrics. For instance:\n",
    "\n",
    "1. **Accuracy:** Measures how many instances the model correctly predicts in classification tasks.\n",
    "2. **Precision and Recall:** Commonly used in information retrieval tasks, precision is the fraction of retrieved instances that are relevant, while recall measures the fraction of relevant instances that are retrieved.\n",
    "3. **F1 Score:** Harmonic mean of precision and recall, often used when both precision and recall are important for a task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8dd0b-6e68-4806-aaa3-0874ece639ee",
   "metadata": {},
   "source": [
    "### Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba15c8-3bae-49e5-a51c-ecc5f9bd5afa",
   "metadata": {},
   "source": [
    "In the world of machine learning:\n",
    "\n",
    "### Intrinsic Measures:\n",
    "check how good a model is by looking at its own performance internally. It's like checking if a car's engine runs smoothly without actually driving the car.\n",
    "\n",
    "Common intrinsic measures in various machine learning tasks include metrics like:\n",
    "\n",
    "* Silhouette Score in Clustering: Measures how well-separated clusters are and how similar the samples are within the same cluster compared to others.\n",
    "* Davies-Bouldin Index in Clustering: Measures the average \"similarity\" between each cluster and its most similar one, where lower values indicate better clustering.\n",
    "* Mean Squared Error (MSE) in Regression: Measures the average squared differences between predicted and actual values.\n",
    "\n",
    "### Extrinsic Measures:\n",
    "test how well a model solves real tasks, like predicting if an email is spam or not. It's like actually driving the car to see how well it handles on the road.\n",
    "\n",
    "So, intrinsic measures focus on the model's own performance, while extrinsic measures see how well the model performs in real tasks or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d01fda-2466-4e9b-a14c-603bbbfc6694",
   "metadata": {},
   "source": [
    "### Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece18ffa-7949-46a2-956b-530142018a63",
   "metadata": {},
   "source": [
    "The confusion matrix in machine learning is used to:\n",
    "\n",
    "- **Purpose:** Summarize the performance of a classification model by presenting the count of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "- **Identifying Strengths and Weaknesses:** It helps in understanding a model's performance by highlighting its strengths and weaknesses. For instance:\n",
    "    - **Strengths:** High counts in the true positive and true negative cells indicate the model's ability to correctly classify instances.\n",
    "    - **Weaknesses:** High false positive and false negative counts reveal areas where the model is making mistakes, such as misclassifying instances.\n",
    "\n",
    "In short, the confusion matrix provides a clear snapshot of a model's performance, allowing for an easy identification of its strengths and weaknesses in classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52a3d5-5583-4308-8747-712947e76f67",
   "metadata": {},
   "source": [
    "### Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b72b14-76c5-4c91-815e-9ace22c5ce0c",
   "metadata": {},
   "source": [
    "\n",
    "1. **Silhouette Score:** The silhouette score measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation). It calculates the average silhouette of all samples. The silhouette score ranges from -1 to 1. A score close to +1 indicates that the sample is well-clustered and lies far from neighboring clusters. A score near 0 implies overlapping clusters, where it's on the boundary. A negative score suggests that samples might be assigned to the wrong cluster.\n",
    "\n",
    "2. **Davies-Bouldin Index:** The Davies-Bouldin index measures the average similarity between each cluster and its most similar one. It considers both the size and dispersion of clusters. Lower index values indicate better clustering. A value closer to 0 represents good separation and distinct clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015aaae-aa3e-4e9c-ae3c-c7a0e6e3d503",
   "metadata": {},
   "source": [
    "### Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c639e46-9127-4122-b9fb-a3b7fdee92c5",
   "metadata": {},
   "source": [
    "| **Limitations of Accuracy** | **Addressing these Limitations** |\n",
    "|----------------------------|----------------------------------|\n",
    "| Imbalanced Datasets         | - Precision and Recall <br> - F1 Score <br> - Confusion Matrix Analysis |\n",
    "| Ignoring Class Distribution  | - Precision and Recall <br> - F1 Score <br> - ROC Curve and AUC |\n",
    "| Equal Cost Fallacy           | - Cost-Sensitive Evaluation |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97c4ab-45d9-4871-b020-e4f3ae16ebfe",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
